{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone Spyne - Car Segmentation Training\n",
        "\n",
        "Entrainement du modele U-Net sur le dataset Carvana.\n",
        "\n",
        "IMPORTANT : Active le GPU avant de commencer !\n",
        "Menu > Runtime > Change runtime type > A100 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Verifier le GPU\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Installation des dependances\n",
        "!pip install -q segmentation-models-pytorch albumentations kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Configuration Kaggle API\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Credentials Kaggle\n",
        "kaggle_creds = {\"username\": \"rubengareginyan\", \"key\": \"7e3b61a9ded4da719ee5f8fc902bd254\"}\n",
        "\n",
        "# Creer le fichier de config\n",
        "os.makedirs('/root/.config/kaggle', exist_ok=True)\n",
        "with open('/root/.config/kaggle/kaggle.json', 'w') as f:\n",
        "    json.dump(kaggle_creds, f)\n",
        "os.chmod('/root/.config/kaggle/kaggle.json', 0o600)\n",
        "\n",
        "print(\"Kaggle API configuree!\")\n",
        "print(f\"Username: {kaggle_creds['username']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Telecharger le dataset Carvana (environ 15 Go)\n",
        "# IMPORTANT: Accepte d'abord les regles sur https://www.kaggle.com/c/carvana-image-masking-challenge/rules\n",
        "\n",
        "!kaggle competitions download -c carvana-image-masking-challenge -f train.zip\n",
        "!kaggle competitions download -c carvana-image-masking-challenge -f train_masks.zip\n",
        "\n",
        "print(\"\\nTelechargement termine !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Extraire les fichiers\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs('data/train', exist_ok=True)\n",
        "os.makedirs('data/train_masks', exist_ok=True)\n",
        "\n",
        "print(\"Extraction des images...\")\n",
        "with zipfile.ZipFile('train.zip', 'r') as z:\n",
        "    z.extractall('data/')\n",
        "\n",
        "print(\"Extraction des masques...\")\n",
        "with zipfile.ZipFile('train_masks.zip', 'r') as z:\n",
        "    z.extractall('data/')\n",
        "\n",
        "# Verifier la structure\n",
        "print(\"\\nContenu de data/:\")\n",
        "for item in os.listdir('data/'):\n",
        "    path = os.path.join('data/', item)\n",
        "    if os.path.isdir(path):\n",
        "        count = len(os.listdir(path))\n",
        "        print(f\"  {item}/ ({count} fichiers)\")\n",
        "    else:\n",
        "        print(f\"  {item}\")\n",
        "\n",
        "# Compter les images\n",
        "train_path = 'data/train' if os.path.exists('data/train') else 'data/'\n",
        "mask_path = 'data/train_masks' if os.path.exists('data/train_masks') else 'data/'\n",
        "\n",
        "n_images = len([f for f in os.listdir(train_path) if f.endswith('.jpg')])\n",
        "n_masks = len([f for f in os.listdir(mask_path) if f.endswith('.gif') or f.endswith('.png')])\n",
        "print(f\"\\n{n_images} images, {n_masks} masques\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Dataset & DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Detecter les chemins corrects\n",
        "if os.path.exists('data/train') and len(os.listdir('data/train')) > 0:\n",
        "    IMAGES_DIR = 'data/train'\n",
        "    MASKS_DIR = 'data/train_masks'\n",
        "else:\n",
        "    IMAGES_DIR = 'data'\n",
        "    MASKS_DIR = 'data'\n",
        "\n",
        "print(f\"Images: {IMAGES_DIR}\")\n",
        "print(f\"Masks: {MASKS_DIR}\")\n",
        "\n",
        "class CarvanaDataset(Dataset):\n",
        "    def __init__(self, images_dir, masks_dir, transform=None):\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.masks_dir = Path(masks_dir)\n",
        "        self.transform = transform\n",
        "        \n",
        "        # Trouver toutes les images jpg\n",
        "        self.images = sorted([f for f in self.images_dir.glob('*.jpg')])\n",
        "        print(f\"{len(self.images)} images trouvees dans {images_dir}\")\n",
        "        \n",
        "        if len(self.images) == 0:\n",
        "            print(\"ERREUR: Aucune image trouvee!\")\n",
        "            print(f\"Contenu du dossier: {list(self.images_dir.iterdir())[:10]}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        \n",
        "        # Chercher le masque (peut etre .gif ou .png)\n",
        "        mask_name = img_path.stem + '_mask'\n",
        "        mask_path = self.masks_dir / (mask_name + '.gif')\n",
        "        if not mask_path.exists():\n",
        "            mask_path = self.masks_dir / (mask_name + '.png')\n",
        "        \n",
        "        image = np.array(Image.open(img_path).convert('RGB'))\n",
        "        mask = np.array(Image.open(mask_path).convert('L'))\n",
        "        \n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "        \n",
        "        return image, mask.unsqueeze(0).float() / 255.0\n",
        "\n",
        "# Augmentations\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(512, 512),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Creer dataset\n",
        "full_dataset = CarvanaDataset(IMAGES_DIR, MASKS_DIR, transform=train_transform)\n",
        "\n",
        "if len(full_dataset) == 0:\n",
        "    raise ValueError(\"Dataset vide! Verifie que l'extraction a fonctionne.\")\n",
        "\n",
        "# Split train/val (90/10)\n",
        "train_size = int(0.9 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoaders\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"\\nTrain: {len(train_dataset)} | Val: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Modele U-Net avec ResNet34 pre-entraine\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Modele cree: {params:,} parametres\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Loss & Metrics\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.sigmoid(pred).view(-1)\n",
        "        target = target.view(-1)\n",
        "        intersection = (pred * target).sum()\n",
        "        return 1 - (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.dice = DiceLoss()\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        return self.bce(pred, target) + self.dice(pred, target)\n",
        "\n",
        "def dice_score(pred, target, threshold=0.5):\n",
        "    pred = (torch.sigmoid(pred) > threshold).float().view(-1)\n",
        "    target = target.view(-1)\n",
        "    intersection = (pred * target).sum()\n",
        "    return (2. * intersection) / (pred.sum() + target.sum() + 1e-6)\n",
        "\n",
        "print(\"Loss functions definies\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. ENTRAINEMENT\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "EPOCHS = 30\n",
        "LR = 1e-4\n",
        "\n",
        "criterion = CombinedLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
        "\n",
        "best_dice = 0\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_dice': []}\n",
        "\n",
        "print(\"Debut de l'entrainement\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # TRAIN\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for images, masks in pbar:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "    \n",
        "    train_loss /= len(train_loader)\n",
        "    \n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_dice = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, masks).item()\n",
        "            val_dice += dice_score(outputs, masks).item()\n",
        "    \n",
        "    val_loss /= len(val_loader)\n",
        "    val_dice /= len(val_loader)\n",
        "    scheduler.step(val_dice)\n",
        "    \n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_dice'].append(val_dice)\n",
        "    \n",
        "    print(f\"   Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
        "    \n",
        "    if val_dice > best_dice:\n",
        "        best_dice = val_dice\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'dice_score': val_dice,\n",
        "        }, 'car_segmentation_best.pth')\n",
        "        print(f\"   Nouveau meilleur modele sauvegarde! (Dice: {val_dice:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(f\"Entrainement termine! Meilleur Dice: {best_dice:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Courbes d'apprentissage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax1.plot(history['train_loss'], label='Train Loss', color='#10b981')\n",
        "ax1.plot(history['val_loss'], label='Val Loss', color='#ef4444')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Loss par Epoch')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.plot(history['val_dice'], label='Val Dice', color='#3b82f6')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Dice Score')\n",
        "ax2.set_title('Dice Score par Epoch')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 11. Test sur quelques images\n",
        "checkpoint = torch.load('car_segmentation_best.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "test_images = sorted(os.listdir('data/train'))[:6]\n",
        "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
        "\n",
        "for i, img_name in enumerate(test_images):\n",
        "    img = Image.open(f'data/train/{img_name}').convert('RGB')\n",
        "    img_np = np.array(img)\n",
        "    \n",
        "    augmented = val_transform(image=img_np)\n",
        "    input_tensor = augmented['image'].unsqueeze(0).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
        "    \n",
        "    mask_name = img_name.replace('.jpg', '_mask.gif')\n",
        "    real_mask = np.array(Image.open(f'data/train_masks/{mask_name}').convert('L').resize((512, 512)))\n",
        "    \n",
        "    axes[0, i].imshow(img.resize((512, 512)))\n",
        "    axes[0, i].set_title('Image')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    axes[1, i].imshow(pred_mask, cmap='gray')\n",
        "    axes[1, i].set_title('Prediction')\n",
        "    axes[1, i].axis('off')\n",
        "    \n",
        "    axes[2, i].imshow(real_mask, cmap='gray')\n",
        "    axes[2, i].set_title('Ground Truth')\n",
        "    axes[2, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12. Exporter et telecharger le modele\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'dice_score': best_dice,\n",
        "    'encoder': 'resnet34',\n",
        "    'image_size': 512,\n",
        "}, 'car_segmentation_final.pth')\n",
        "\n",
        "print(f\"Modele sauvegarde: car_segmentation_final.pth\")\n",
        "print(f\"Dice Score: {best_dice:.4f}\")\n",
        "\n",
        "# Telecharger\n",
        "from google.colab import files\n",
        "files.download('car_segmentation_final.pth')\n",
        "\n",
        "print(\"\\nModele telecharge!\")\n",
        "print(\"\\nPour l'utiliser dans Clone Spyne:\")\n",
        "print(\"1. Place le fichier dans apps/api/python/\")\n",
        "print(\"2. python segment_with_trained.py car_segmentation_final.pth image.jpg\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
